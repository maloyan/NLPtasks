{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('scripts/dialent/task1/')\n",
    "sys.path.append('scripts/dialent/')\n",
    "sys.path.append('scripts/')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tkn_dict(u):\n",
    "    d = dict()\n",
    "    for i in range(len(u)):\n",
    "        tokens = u[i].tokens\n",
    "        for j in tokens:\n",
    "            d[int(j.id)] = j.text\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_bin(x):\n",
    "    if x == 'LOC':\n",
    "        return 0\n",
    "    elif x == 'LOCORG':\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(u):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(u)):\n",
    "        res = u[i].makeTokenSets()\n",
    "        for j in range(len(res)):\n",
    "            token = res[j].toInlineString()\n",
    "            split = token.split()\n",
    "            token_id = int(str(res[j]).split('#')[-1][:-2])\n",
    "            df = df.append({'tokens': split[4:], \n",
    "                            'tokens_id': token_id,\n",
    "                            'obj_id': int(split[1]),\n",
    "                            'ne_bin': ne_bin(str(split[0]))}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX = 3\n",
    "def get_from_dict_dev(id_d):\n",
    "    d = tkn_dev_dict\n",
    "    ans = str()\n",
    "    for i in range(-CTX, CTX):\n",
    "        if id_d + i in d:\n",
    "            ans += \" \" + str(d[id_d + i])\n",
    "    return ans\n",
    "\n",
    "def get_from_dict_test(id_d):\n",
    "    d = tkn_test_dict\n",
    "    ans = str()\n",
    "    for i in range(-CTX, CTX):\n",
    "        if id_d + i in d:\n",
    "            ans += \" \" + str(d[id_d + i])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n"
     ]
    }
   ],
   "source": [
    "u_dev = util.loadAllStandard('./devset/')\n",
    "u_test = util.loadAllStandard('./testset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn_dev_dict = tkn_dict(u_dev)\n",
    "tkn_test_dict = tkn_dict(u_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = get_df(u_dev)\n",
    "df_dev['ctx'] = df_dev['tokens_id'].apply(get_from_dict_dev)\n",
    "df_dev = df_dev[df_dev['ne_bin'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_df(u_test)\n",
    "df_test['ctx'] = df_test['tokens_id'].apply(get_from_dict_test)\n",
    "df_test = df_test[df_test['ne_bin'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_dev.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                      min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                      use_idf=1, smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(df_dev['ctx'])\n",
    "test_term_doc = vec.transform(df_test['ctx']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev = df_dev['ne_bin']\n",
    "Y_test = df_test['ne_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = {\n",
    "    'learning_rate': 0.08,\n",
    "    'max_depth': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n",
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n",
      "Type    P        R        F1       TP1      TP2      In Std.  In Test.\n",
      "per        0.9993   0.9993   0.9993  1342.00  1342.00     1343     1343\n",
      "loc        0.7285   0.6969   0.7123   417.43   417.43      599      573\n",
      "org        0.9895   0.9895   0.9895  1557.55  1557.55     1574     1574\n",
      "locorg     0.6686   0.8070   0.7313   510.83   510.83      633      764\n",
      "overall    0.8996   0.9224   0.9109  3819.81  3819.81     4141     4246\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(**best_parameters)\n",
    "clf.fit(trn_term_doc, Y_dev)\n",
    "predict = clf.predict(test_term_doc)\n",
    "\n",
    "u = util.loadAllStandard('./testset/')\n",
    "for i in range(len(u)):\n",
    "    res = u[i].makeTokenSets()\n",
    "    row = []\n",
    "    for j in range(len(res)):\n",
    "        token = res[j].toInlineString()\n",
    "        if token[0] == 'L':\n",
    "            split = token.split()\n",
    "            if predict[df_test['obj_id'] == int(split[1])][0] == 0:\n",
    "                tag = 'LOC'\n",
    "            else:\n",
    "                tag = 'LOCORG'\n",
    "            start = int(split[2][1:-1])\n",
    "            end = int(split[3][:-1])\n",
    "            row.append('%s %d %d\\n' % (tag, start, end-start+1))\n",
    "            #if tag != split[0]:\n",
    "            #    print(token)\n",
    "        else:\n",
    "            split = token.split()\n",
    "            start = int(split[2][1:-1])\n",
    "            end = int(split[3][:-1])\n",
    "            row.append('%s %d %d\\n' % (split[0], start, end-start+1))\n",
    "    with open('./result/' + u[i].name + '.task1', 'w') as f:\n",
    "        f.writelines(row)   \n",
    "\n",
    "!python scripts/t1_eval.py -s ./testset -t ./result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
