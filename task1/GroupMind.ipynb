{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('scripts/dialent/task1/')\n",
    "sys.path.append('scripts/dialent/')\n",
    "sys.path.append('scripts/')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n"
     ]
    }
   ],
   "source": [
    "u_dev = util.loadAllStandard('./devset/')\n",
    "u_test = util.loadAllStandard('./testset//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def get_pos(token):\n",
    "    pos = morph.parse(token)[0].tag.POS\n",
    "    if pos == 'NOUN':\n",
    "        return pos\n",
    "    return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_bin(x):\n",
    "    if x == 'LOC':\n",
    "        return 0\n",
    "    elif x == 'LOCORG':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_bin(x):\n",
    "    if x == 'NOUN':\n",
    "        return 1\n",
    "    if x == 'ADJF':\n",
    "        return 2\n",
    "    if x == 'PRTF':\n",
    "        return 3\n",
    "    if x == 'VERB':\n",
    "        return 4\n",
    "    if x == 'CONJ':\n",
    "        return 5\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(u):\n",
    "    df = pd.DataFrame(columns=['tokens', 'tokens_id', 'start', 'end', 'ne'])\n",
    "    for i in range(len(u)):\n",
    "        res = u[i].makeTokenSets()\n",
    "        for j in range(len(res)):\n",
    "            token = res[j].toInlineString()\n",
    "            split = token.split()\n",
    "            df = df.append({'tokens': split[4:], 'first_token': str(split[4].split('\"')[1]), 'tokens_id': int(split[1]), 'start': int(split[2][1:-1]), \\\n",
    "               'end': int(split[3][:-1]), 'ne': str(split[0])}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = get_df(u_dev)\n",
    "df_dev = df_dev[(df_dev['ne'] == 'LOC') | (df_dev['ne'] == 'LOCORG')]\n",
    "df_dev['ne_bin'] = df_dev['ne'].apply(ne_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_df(u_test)\n",
    "df_test = df_test[(df_test['ne'] == 'LOC') | (df_test['ne'] == 'LOCORG')]\n",
    "df_test['ne_bin'] = df_test['ne'].apply(ne_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_dev.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), analyzer='char', tokenizer=tokenize,\n",
    "               min_df=2, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(df_dev['first_token'])\n",
    "test_term_doc = vec.transform(df_test['first_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dev['length'] = df_dev['end'] - df_dev['start'] + 1\n",
    "\n",
    "#df_dev['pos'] = df_dev['first_token'].apply(get_pos)\n",
    "#df_dev['pos_bin'] = df_dev['pos'].apply(pos_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dev = pd.concat([df_dev, pd.DataFrame(trn_term_doc.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test['length']= df_test['end'] - df_test['start'] + 1\n",
    "\n",
    "#df_test['pos'] = df_test['first_token'].apply(get_pos)\n",
    "#df_test['pos_bin'] = df_test['pos'].apply(pos_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = pd.concat([df_test, pd.DataFrame(test_term_doc.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev = df_dev['ne_bin']\n",
    "Y_test = df_test['ne_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082, 1574)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_dev), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_dev = df_dev.drop(labels=['tokens', 'ne', 'ne_bin','first_token', 'pos'], axis=1)\n",
    "#X_test = df_test.drop(labels=['tokens', 'ne', 'ne_bin','first_token', 'pos'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\\n       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\\n       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\\n       silent=True, subsample=1)\\n\""
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {\n",
    "    'colsample_bytree': np.arange(0.7, 0.9, 0.05), #[0.6, 0.8, 1.0],\n",
    "    'gamma': np.arange(1.4, 1.6, 0.05), #[0.0, 0.5, 1, 1.5, 2, 5],\n",
    "    'learning_rate': np.arange(0.1, 0.3, 0.05), #[0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    'max_depth': np.arange(1, 5, 1),\n",
    "    'subsample': np.arange(0.7, 0.9, 0.1) #[0.4, 0.5, 0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(Y_dev, n_folds=2, shuffle=True), \n",
    "                   #scoring='f1',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "\n",
    "'''\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1200 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=5)]: Done 264 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=5)]: Done 670 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=5)]: Done 1236 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=5)]: Done 1966 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=5)]: Done 2400 out of 2400 | elapsed:   50.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[1 1 ..., 0 1], n_folds=2, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=5,\n",
       "       param_grid={'colsample_bytree': array([ 0.7 ,  0.75,  0.8 ,  0.85,  0.9 ]), 'gamma': array([ 1.4 ,  1.45,  1.5 ,  1.55,  1.6 ]), 'learning_rate': array([ 0.1 ,  0.15,  0.2 ,  0.25]), 'max_depth': array([1, 2, 3, 4]), 'subsample': array([ 0.7,  0.8,  0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trn_term_doc, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"= {\\n    'colsample_bytree': 0.8,\\n     'gamma': 1.4,\\n     'learning_rate': 0.1,\\n     'max_depth': 5,\\n     'subsample': 0.8\\n}\\n\""
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = {\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.8,\n",
    "     'gamma': 1.4,\n",
    "     'learning_rate': 0.1,\n",
    "     'max_depth': 5,\n",
    "     'subsample': 0.8\n",
    "}\n",
    "\n",
    "'''= {\n",
    "    'colsample_bytree': 0.8,\n",
    "     'gamma': 1.4,\n",
    "     'learning_rate': 0.1,\n",
    "     'max_depth': 5,\n",
    "     'subsample': 0.8\n",
    "}\n",
    "'''\n",
    "#0.903\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(**best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eta=0.01, gamma=1.4, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trn_term_doc, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(test_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7242693773824651\n"
     ]
    }
   ],
   "source": [
    "ans = np.array(Y_test)\n",
    "a = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == ans[i]:\n",
    "        a += 1\n",
    "print(a / len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n"
     ]
    }
   ],
   "source": [
    "u = util.loadAllStandard('./testset/')\n",
    "for i in range(len(u)):\n",
    "    res = u[i].makeTokenSets()\n",
    "    row = []\n",
    "    for j in range(len(res)):\n",
    "        token = res[j].toInlineString()\n",
    "        if token[0] == 'L':\n",
    "            #Заменить в этом ифе код на код предсказывания\n",
    "            split = token.split()\n",
    "            if predict[df_test['tokens_id'] == int(split[1])][0] == 0:\n",
    "                tag = 'LOC'\n",
    "            else:\n",
    "                tag = 'LOCORG'\n",
    "            start = int(split[2][1:-1])\n",
    "            end = int(split[3][:-1])\n",
    "            row.append('%s %d %d\\n' % (tag, start, end-start+1))\n",
    "        else:\n",
    "            split = token.split()\n",
    "            start = int(split[2][1:-1])\n",
    "            end = int(split[3][:-1])\n",
    "            row.append('%s %d %d\\n' % (split[0], start, end-start+1))\n",
    "    with open('./result/' + u[i].name + '.task1', 'w') as f:\n",
    "        f.writelines(row)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n",
      "Type    P        R        F1       TP1      TP2      In Std.  In Test.\n",
      "per        0.9993   0.9993   0.9993  1342.00  1342.00     1343     1343\n",
      "loc        0.6813   0.6825   0.6819   408.80   408.80      599      600\n",
      "org        0.9895   0.9895   0.9895  1557.55  1557.55     1574     1574\n",
      "locorg     0.6693   0.7899   0.7246   500.00   500.00      633      747\n",
      "overall    0.8929   0.9177   0.9052  3800.35  3800.35     4141     4256\n"
     ]
    }
   ],
   "source": [
    "!python scripts/t1_eval.py -s ./testset -t ./result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
